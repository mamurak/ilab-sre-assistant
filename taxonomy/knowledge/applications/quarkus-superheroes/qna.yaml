version: 3
domain: Software applications
created_by: Max Murakami
seed_examples:
  - context: |
      ## Introduction

      This is a sample application demonstrating Quarkus features and best
       practices. The application allows superheroes to fight against
       supervillains. The application consists of several microservices,
       communicating either synchronously via REST or asynchronously using
       Kafka. All the data used by the applications are [on the `characterdata`
      branch]
      (https://github.com/quarkusio/quarkus-super-heroes/tree/characterdata)
       of this repository.

      This is **NOT** the workshop with the step-by-step instructions. If you
       are looking for the Quarkus Super Heroes workshop, you can find it at
       https://quarkus.io/quarkus-workshops/super-heroes/.

      This is **NOT** a single multi-module project. Each service in the system
       is its own sub-directory of this parent directory. As such, each
       individual service needs to be run on its own.

      The base JVM version for all the applications is Java 21.
    questions_and_answers:
      - question: |
          What's the purpose of this application?
        answer: |
          This application is an example of a Quarkus application that consists
           of multiple microservices.
      - question: |
          How do the application components communicate with each other?
        answer: |
          Communication between the microservices is mediated through
           synchronous HTTP calls as well as asynchronous messaging through
           Kafka.
      - question: |
          What is the underlying framework of this application?
        answer: |
          The application is implemented in Quarkus based on Java 21.
  - context: |
      - Fights Messaging (fights-messaging)
          - The message broker for asynchronous message streaming between the
            Fight REST API and the Statistics microservices.
          - Running as a small-scale, single-node Kafka cluster via a Strimzi
            deployment in KRaft (Kafka Raft) mode.
          - Fights Messaging does not consume a PVC, therefore streaming is
            non-persistent. Due to this and the fact that there are no
            redundant Kafka nodes, messages are lost during restarts of the
            Fights Messaging pod.
          - Check out the Strimzi documentation regarding configuration of
            Fights Messaging.
    questions_and_answers:
      - question: |
          What does the Fights Messaging application component do?
        answer: |
          Fights Messaging is the central asynchronous communication interface
           between the Fight REST API and the Statistics component.
      - question: |
          How is Fights Messaging implemented?
        answer: |
          Fights Messaging is a Kafka instance that has been packaged through
           Strimzi as a very small KRaft (Kafka Raft) deployment.
      - question: |
          Are there any important limitations of the Fights Messaging component
           that I should know?
        answer: |
          Even though Fights Messaging is a Kafka-based message broker,
           messages are not retained since it doesn't consume persistent
           volumes.
  - context: |
      ## Deploying to Kubernetes
      Pre-built images for all of the applications in the system can be found
       at [`quay.io/quarkus-super-heroes`]
      (http://quay.io/quarkus-super-heroes).

      Deployment descriptors for these images are provided in the
       [`deploy/k8s`](deploy/k8s) directory. There are versions for
       [OpenShift](https://www.openshift.com),
      [Minikube](https://quarkus.io/guides/deploying-to-kubernetes#
      deploying-to-minikube), [Kubernetes](https://www.kubernetes.io), and
       [Knative](https://knative.dev).

      > [!NOTE]
      > The [Knative](https://knative.dev/docs/) variant can be used on any
       Knative installation that runs on top of Kubernetes or OpenShift. For
       OpenShift, you need [OpenShift Serverless](https://docs.openshift.com/
      serverless/latest/about/about-serverless.html) installed from the
       OpenShift operator catalog. Using Knative has the benefit that services
       are scaled down to zero replicas when they are not used.

      The only real difference between the Minikube and Kubernetes descriptors
       is that all the application `Service`s in the Minikube descriptors use
       `type: NodePort` so that a list of all the applications can be obtained
       simply by running `minikube service list`.

      > [!NOTE]
      > If you'd like to deploy each application directly from source to
       Kubernetes, please follow the guide located within each application's
       folder (i.e. [`event-statistics`](event-statistics/README.md#
      deploying-directly-via-kubernetes-extensions), [`rest-fights`]
      (rest-fights/README.md#deploying-directly-via-kubernetes-extensions),
       [`rest-heroes`](rest-heroes/README.md#
      deploying-directly-via-kubernetes-extensions),
       [`rest-villains`](rest-villains/README.md#
      deploying-directly-via-kubernetes-extensions),
       [`rest-narration`](rest-narration/README.md#
      deploying-directly-via-kubernetes-extensions),
       [`grpc-locations`](grpc-locations/README.md#
      deploying-directly-via-kubernetes-extensions)).
    questions_and_answers:
      - question: |
          Where are the container images of this application stored?
        answer: |
          The container images of the application are located under
           `quay.io/quarkus-super-heroes`.
      - question: |
          Can I run this application with Knative on OpenShift?
        answer: |
          For deployments on OpenShift the OpenShift distribution of Knative,
           OpenShift Serverless, needs to be used.
      - question: |
          Is there an alternative to deploying the application via the
           pre-built container images?
        answer: |
          Yes, the application can be deployed to Kubernetes directly from
           source.
  - context: |
      ### Fights Messaging Troubleshooting
      The Fights Messaging pod is configured as a small-scale development
       instance. For fault-tolerance and high-performance streaming under load,
       we recommend replacing this single-node deployment with a distributed
       streaming architecture and rely on Strimzi for deployment and
       automation.

      Under certain circumstances, you may find the `fights-messaging` pod
       crash-looping with the following error message:
      ```
      java.lang.OutOfMemoryError: Java heap space
      ```
      This indicates that the pod's JVM heap memory allocation needs to be
       increased.
      To do this:
      - Find the corresponding JVM setting in the `fights-messaging` deployment
        YAML under `spec.template.spec.containers[0].env` under name
        `KAFKA_HEAP_OPTS`.
      - Increase the value of the `Xmx` argument. An increase to 256 MB is
        sufficient in most cases:
      ```
      - name: KAFKA_HEAP_OPTS
        value: '-Xmx256M -Xms128M'
      ```
    questions_and_answers:
      - question: |
          What should I do if the fights-messaging pod keeps crashing with this
           error message:
          ```
          java.lang.OutOfMemoryError: Java heap space
          ```
        answer: |
          Update the value of the `KAFKA_HEAP_OPTS` environment variable in the
           `fights-messaging` deployment spec under
           `spec.template.spec.containers[0].env`. Try increasing `Xmx` to
           256 MB like this:
          ```
          - name: KAFKA_HEAP_OPTS
            value: '-Xmx256M -Xms128M'
          ```
      - question: |
          What do I see this error message in the fights-messaging pod logs:
          ```
          java.lang.OutOfMemoryError: Java heap space
          ```
        answer: |
          If `fights-messaging` logs this error message, it means that its JVM
           heap size is too small. Try increasing it by updating the value of
           the `KAFKA_HEAP_OPTS` environment variable in the `fights-messaging`
           deployment spec under `spec.template.spec.containers[0].env`. A
           `Xmx` value of 256 MB usually works:
          ```
          - name: KAFKA_HEAP_OPTS
            value: '-Xmx256M -Xms128M'
          ```
      - question: |
          How can I fix issues with the Java heap space in the fights-messaging
           pod?
        answer: |
          Update the value of the `KAFKA_HEAP_OPTS` environment variable in the
           `fights-messaging` deployment spec under
           `spec.template.spec.containers[0].env`. Try increasing `Xmx` to
           256 MB like this:
          ```
          - name: KAFKA_HEAP_OPTS
            value: '-Xmx256M -Xms128M'
          ```
  - context: |
      ### Monitoring
      There are also Kubernetes deployment descriptors for monitoring with
       [OpenTelemetry](https://opentelemetry.io), [Prometheus]
      (https://prometheus.io), and [Jaeger](https://www.jaegertracing.io) in
       the [`deploy/k8s` directory](deploy/k8s) ([`monitoring-openshift.yml`]
      (deploy/k8s/monitoring-openshift.yml), [`monitoring-minikube.yml`]
      (deploy/k8s/monitoring-minikube.yml), [`monitoring-kubernetes.yml`]
      (deploy/k8s/monitoring-kubernetes.yml)). Each descriptor contains the
       resources necessary to monitor and gather metrics and traces from all
       of the applications in the system. Deploy the appropriate descriptor to
       your cluster if you want it.

      The OpenShift descriptor will automatically create `Route`s for
       Prometheus and Jaeger. On Kubernetes/Minikube you may need to expose the
       Prometheus and Jaeger services in order to access them from outside your
       cluster, either by using an `Ingress` or by using
       `kubectl port-forward`. On Minikube, the Prometheus and Jaeger
       `Service`s are also exposed as a `NodePort`.

      > [!WARNING]
      > These descriptors are **NOT** considered to be production-ready. They
      > are basic enough to deploy Prometheus, Jaeger, and the
      > [OpenTelemetry Collector](https://opentelemetry.io/docs/collector) with
      > as little configuration as possible. They are not highly-available and
      > does not use any Kubernetes operators for management or monitoring.
      > They also only uses ephemeral storage.
      >
      > For production-ready Prometheus instances, please see the
      > [Prometheus Operator documentation]
      >(https://operatorhub.io/operator/prometheus) for how to properly deploy
      > and configure production-ready instances.
      >
      > For production-ready Jaeger instances, please see the
      > [Jaeger Operator documentation](https://operatorhub.io/operator/jaeger)
      > for how to properly deploy and configure production-ready instances.
      >
      > For production-ready OpenTelemetry Collector instances, please see the
      > [OpenTelemetry Operator documentation]
      >(https://operatorhub.io/operator/opentelemetry-operator) for how to
      > properly deploy and configure production-ready instances.
    questions_and_answers:
      - question: |
          How can I monitor this application on Kubernetes?
        answer: |
          There are pre-configured monitoring integrations with OpenTelemetry,
           Prometheus, and Jaeger.
      - question: |
          Which limitations of the pre-configured monitoring integrations
           should I be aware of?
        answer: |
          The pre-configured monitoring integrations are not production-grade
           since they don't leverage persistence nor fault tolerance.
      - question: |
          How should I configure monitoring for the application in production?
        answer: |
          Refer to the respective documentation for OpenTelemetry, Prometheus,
           and Jaeger for instructions.
document_outline: Documentation of the Quarkus Super Heroes application
document:
  repo: https://github.com/mamurak/ilab-sre-assistant.git
  commit: 
  patterns:
    - "source_docs/quarkus-super-heroes.md"
